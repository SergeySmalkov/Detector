{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe24387",
   "metadata": {},
   "source": [
    "exponential distribution with lambda  for time between deals, uniform distribution for sizes, ranndom number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1a3bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         timestamp           size\n",
      "0    1970-01-01 00:00:06.020242861 7534279.469142\n",
      "1    1970-01-01 00:00:08.653734248 7689228.052154\n",
      "2    1970-01-01 00:00:10.479619356 6585405.498160\n",
      "3    1970-01-01 00:00:10.818869097 7661159.561840\n",
      "4    1970-01-01 00:00:11.158061681 8459214.550856\n",
      "...                            ...            ...\n",
      "1097 1970-01-01 00:36:20.746640527 4861305.366019\n",
      "1098 1970-01-01 00:36:21.608591809 9207396.582687\n",
      "1099 1970-01-01 00:36:21.727757826  400592.150448\n",
      "1100 1970-01-01 00:36:28.681926259 2914609.843477\n",
      "1101 1970-01-01 00:36:32.986568199 2075410.154516\n",
      "\n",
      "[1102 rows x 2 columns]\n",
      "                         timestamp           size\n",
      "0    1970-01-01 00:00:04.379424256 2381467.298510\n",
      "1    1970-01-01 00:00:13.179507204 9084345.610359\n",
      "2    1970-01-01 00:00:13.497896699 4680691.074274\n",
      "3    1970-01-01 00:00:14.338866457 4662994.663099\n",
      "4    1970-01-01 00:00:16.705205583 7605756.663977\n",
      "...                            ...            ...\n",
      "1430 1970-01-01 00:40:07.513642909 5528149.204369\n",
      "1431 1970-01-01 00:40:09.745164373 7406636.070003\n",
      "1432 1970-01-01 00:40:12.739562601 4850180.390222\n",
      "1433 1970-01-01 00:40:14.987740273  854031.216224\n",
      "1434 1970-01-01 00:40:15.244644743 9724613.927818\n",
      "\n",
      "[1435 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "# Set the random seed for reproducibility (optional)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a random number of rows between 1000 and 1500\n",
    "num_rows = np.random.randint(1000, 1500)\n",
    "num_rows2 = np.random.randint(1000, 1500)\n",
    "\n",
    "# Generate random timestamps following an exponential distribution\n",
    "lambda_param = 0.5  # Adjust this parameter to control the time between deals\n",
    "lambda_param2 = 0.6  # Adjust this parameter to control the time between deals\n",
    "\n",
    "timestamps = np.cumsum(np.random.exponential(scale=1 / lambda_param, size=num_rows))\n",
    "timestamps2 = np.cumsum(np.random.exponential(scale=1 / lambda_param2, size=num_rows2))\n",
    "\n",
    "# Generate random deal sizes between 1 and 10,000,000\n",
    "sizes = np.random.uniform(low=1, high=10000000, size=num_rows)\n",
    "sizes2 = np.random.uniform(low=1, high=10000000, size=num_rows2)\n",
    "\n",
    "# Create a DataFrame with the generated data\n",
    "df = pd.DataFrame({'timestamp': timestamps, 'size': sizes})\n",
    "df2 = pd.DataFrame({'timestamp': timestamps2, 'size': sizes2})\n",
    "\n",
    "# Optional: Convert the 'timestamp' column to a datetime data type\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df2['timestamp'] = pd.to_datetime(df2['timestamp'], unit='s')\n",
    "print(df)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f5e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         timestamp           size\n",
      "0    1970-01-01 00:00:06.020242861 7534279.469142\n",
      "1    1970-01-01 00:00:08.653734248 7689228.052154\n",
      "2    1970-01-01 00:00:10.479619356 6585405.498160\n",
      "3    1970-01-01 00:00:10.818869097 7661159.561840\n",
      "4    1970-01-01 00:00:11.158061681 8459214.550856\n",
      "...                            ...            ...\n",
      "1274 1970-01-01 04:00:24.159666814 2973724.535851\n",
      "1275 1970-01-01 04:03:34.210828075 4974778.650614\n",
      "1276 1970-01-01 04:06:44.262074120 1602100.388387\n",
      "1277 1970-01-01 04:09:54.313304742 2736309.476381\n",
      "1278 1970-01-01 04:13:04.364594721  856484.276046\n",
      "\n",
      "[1279 rows x 2 columns]\n",
      "                         timestamp           size\n",
      "0    1970-01-01 00:00:04.379424256 2381467.298510\n",
      "1    1970-01-01 00:00:13.179507204 9084345.610359\n",
      "2    1970-01-01 00:00:13.497896699 4680691.074274\n",
      "3    1970-01-01 00:00:14.338866457 4662994.663099\n",
      "4    1970-01-01 00:00:16.705205583 7605756.663977\n",
      "...                            ...            ...\n",
      "1607 1970-01-01 04:00:24.159635227 3186768.250008\n",
      "1608 1970-01-01 04:03:34.210828973 1160975.802488\n",
      "1609 1970-01-01 04:06:44.262076340 4495190.257835\n",
      "1610 1970-01-01 04:09:54.313377430 3437359.465850\n",
      "1611 1970-01-01 04:13:04.364611344 5292694.586425\n",
      "\n",
      "[1612 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's append a couple of TWAPs for the test case\n",
    "# Constants\n",
    "K = 3 #number of TWAPS\n",
    "LOW_CLIP_NUM = 10\n",
    "HIGH_CLIP_NUM = 80\n",
    "LOW_CLIP_SIZE = 1.0 #only half of the clip\n",
    "HIGH_CLIP_SIZE = 5000000.0 #only half of the clip\n",
    "LOW_NOISE = -0.0001 / (24*60*60)  # Converted to days as pandas Timestamps are in days\n",
    "HIGH_NOISE = 0.0001 / (24*60*60)  # Converted to days\n",
    "LOW_TWAP_WINDOW = 1.0 / (24*60*60)  # Converted to days\n",
    "HIGH_HIGH_TWAP_WINDOW = 800.0 / (24*60*60)  # Converted to days\n",
    "\n",
    "# Initialize lists to hold the new data\n",
    "new_timestamps1 = []\n",
    "new_sizes1 = []\n",
    "new_timestamps2 = []\n",
    "new_sizes2 = []\n",
    "\n",
    "# Generate the data for K TWAPs\n",
    "for _ in range(K):\n",
    "    num_clips = np.random.randint(LOW_CLIP_NUM, HIGH_CLIP_NUM+1)\n",
    "    clip_size = np.random.uniform(LOW_CLIP_SIZE, HIGH_CLIP_SIZE)\n",
    "    timestamp1 = df.sample(n=1, random_state=1)['timestamp'].values[0]\n",
    "    window_twap = pd.to_timedelta(np.random.uniform(LOW_TWAP_WINDOW, HIGH_HIGH_TWAP_WINDOW), 'days')\n",
    "    \n",
    "    for _ in range(num_clips):\n",
    "        # Generate the sizes approximately equal to the clip size in sum\n",
    "        size1 = clip_size * np.random.uniform(0.0, 2.0)\n",
    "        size2 = (clip_size * 2 - size1) * np.random.uniform(0.99, 1.01) \n",
    "\n",
    "        # Generate the timestamps\n",
    "        timestamp1 += window_twap\n",
    "        timestamp1 += pd.to_timedelta(np.random.uniform(LOW_NOISE, HIGH_NOISE), 'days')\n",
    "        timestamp2 = timestamp1 + pd.to_timedelta(np.random.uniform(LOW_NOISE, HIGH_NOISE), 'days')\n",
    "\n",
    "        # Append to the lists\n",
    "        new_timestamps1.append(timestamp1)\n",
    "        new_sizes1.append(size1)\n",
    "        new_timestamps2.append(timestamp2)\n",
    "        new_sizes2.append(size2)\n",
    "\n",
    "# Create new dataframes and append to the original dataframes\n",
    "new_df1 = pd.DataFrame({'timestamp': new_timestamps1, 'size': new_sizes1})\n",
    "new_df2 = pd.DataFrame({'timestamp': new_timestamps2, 'size': new_sizes2})\n",
    "\n",
    "df = pd.concat([df, new_df1], ignore_index=True)\n",
    "df2 = pd.concat([df2, new_df2], ignore_index=True)\n",
    "\n",
    "# Sort by timestamp\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "df2 = df2.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(df)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3388b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         timestamp            sum\n",
      "0    1970-01-01 00:00:06.020242861 7534279.469142\n",
      "1    1970-01-01 00:00:08.653734248 7689228.052154\n",
      "2    1970-01-01 00:00:10.479619356 6585405.498160\n",
      "3    1970-01-01 00:00:10.818869097 7661159.561840\n",
      "4    1970-01-01 00:00:11.158061681 8459214.550856\n",
      "...                            ...            ...\n",
      "2886 1970-01-01 04:00:24.159635227 3186768.250008\n",
      "2887 1970-01-01 04:03:34.210828973 1160975.802488\n",
      "2888 1970-01-01 04:06:44.262076340 4495190.257835\n",
      "2889 1970-01-01 04:09:54.313377430 3437359.465850\n",
      "2890 1970-01-01 04:13:04.364611344 5292694.586425\n",
      "\n",
      "[2891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames based on the exact timestamp match\n",
    "merged_df = pd.merge(df, df2, on='timestamp', how='outer')\n",
    "\n",
    "# Calculate the sum of the 'size' columns when there is a match\n",
    "merged_df['sum'] = merged_df['size_x'].fillna(0) + merged_df['size_y'].fillna(0)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "merged_df = merged_df.drop(['size_x', 'size_y'], axis=1)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ca4e5",
   "metadata": {},
   "source": [
    "if the time between  rows is less than parameter (let's say 0.03ms) then delete two rows and create one with the weighted by size time that and in  sum column it will be sum of these two rows - then proceed to the further rows using the previous row as usual (it might be merged again with the next if satisfies condition) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e91aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01 00:00:06.020242861</td>\n",
       "      <td>7534279.469142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-01 00:00:08.653734248</td>\n",
       "      <td>7689228.052154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-01 00:00:10.479619356</td>\n",
       "      <td>6585405.498160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-01 00:00:10.818869097</td>\n",
       "      <td>7661159.561840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-01 00:00:11.158061681</td>\n",
       "      <td>8459214.550856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>1970-01-01 04:00:24.159635227</td>\n",
       "      <td>3186768.250008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>1970-01-01 04:03:34.210828973</td>\n",
       "      <td>1160975.802488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>1970-01-01 04:06:44.262076340</td>\n",
       "      <td>4495190.257835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>1970-01-01 04:09:54.313377430</td>\n",
       "      <td>3437359.465850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>1970-01-01 04:13:04.364611344</td>\n",
       "      <td>5292694.586425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp            sum\n",
       "0    1970-01-01 00:00:06.020242861 7534279.469142\n",
       "1    1970-01-01 00:00:08.653734248 7689228.052154\n",
       "2    1970-01-01 00:00:10.479619356 6585405.498160\n",
       "3    1970-01-01 00:00:10.818869097 7661159.561840\n",
       "4    1970-01-01 00:00:11.158061681 8459214.550856\n",
       "...                            ...            ...\n",
       "2885 1970-01-01 04:00:24.159635227 3186768.250008\n",
       "2886 1970-01-01 04:03:34.210828973 1160975.802488\n",
       "2887 1970-01-01 04:06:44.262076340 4495190.257835\n",
       "2888 1970-01-01 04:09:54.313377430 3437359.465850\n",
       "2889 1970-01-01 04:13:04.364611344 5292694.586425\n",
       "\n",
       "[2890 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def merge_rows(time, size, time_threshold_sec):\n",
    "    i = 0\n",
    "    merged_time = []\n",
    "    merged_size = []\n",
    "    while i < len(time) - 1:\n",
    "        time_diff = time[i+1] - time[i]\n",
    "        if time_diff <= time_threshold_sec:\n",
    "            total_size = size[i] + size[i+1]\n",
    "            weighted_time = ((time[i] * size[i]) + (time[i+1] * size[i+1])) / total_size\n",
    "            merged_time.append(weighted_time)\n",
    "            merged_size.append(total_size)\n",
    "            i += 2\n",
    "        else:\n",
    "            merged_time.append(time[i])\n",
    "            merged_size.append(size[i])\n",
    "            i += 1\n",
    "    if i == len(time) - 1:\n",
    "        merged_time.append(time[i])\n",
    "        merged_size.append(size[i])\n",
    "        \n",
    "    return np.array(merged_time), np.array(merged_size)\n",
    "\n",
    "# Convert DataFrame to Numpy arrays\n",
    "time = merged_df['timestamp'].values.astype(float)\n",
    "size = merged_df['sum'].values\n",
    "time_threshold_sec = 0.02\n",
    "merged_time, merged_size = merge_rows(time, size, time_threshold_sec)\n",
    "\n",
    "# Convert the result back to DataFrame\n",
    "df_merged = pd.DataFrame({'timestamp': pd.to_datetime(merged_time), 'sum': merged_size})\n",
    "\n",
    "tolerance = 0.00001\n",
    "if abs(merged_df[\"sum\"].sum() - df_merged[\"sum\"].sum()) > tolerance:\n",
    "    raise AssertionError(\"Sums are not approximately equal.\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dd3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IntervalArray>\n",
      "[(117.347, 1594072.198], (1594072.198, 3412890.333], (3412890.333, 5469755.091], (5469755.091, 7623315.151], (7623315.151, 9995577.033]]\n",
      "Length: 5, dtype: interval[float64, right]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01 00:00:15.300200947</td>\n",
       "      <td>886048.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-01 00:00:19.600865378</td>\n",
       "      <td>776494.269067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-01 00:00:30.222438031</td>\n",
       "      <td>660099.375393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-01 00:00:31.101171259</td>\n",
       "      <td>1109981.876915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-01 00:00:33.719757225</td>\n",
       "      <td>723165.680263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1970-01-01 03:03:23.237805252</td>\n",
       "      <td>1473943.380908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1970-01-01 03:28:43.647401766</td>\n",
       "      <td>207220.291047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1970-01-01 03:31:53.698755793</td>\n",
       "      <td>549768.886057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1970-01-01 03:47:43.954687611</td>\n",
       "      <td>900875.739770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1970-01-01 04:03:34.210828973</td>\n",
       "      <td>1160975.802488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        timestamp            sum\n",
       "0   1970-01-01 00:00:15.300200947  886048.051092\n",
       "1   1970-01-01 00:00:19.600865378  776494.269067\n",
       "2   1970-01-01 00:00:30.222438031  660099.375393\n",
       "3   1970-01-01 00:00:31.101171259 1109981.876915\n",
       "4   1970-01-01 00:00:33.719757225  723165.680263\n",
       "..                            ...            ...\n",
       "573 1970-01-01 03:03:23.237805252 1473943.380908\n",
       "574 1970-01-01 03:28:43.647401766  207220.291047\n",
       "575 1970-01-01 03:31:53.698755793  549768.886057\n",
       "576 1970-01-01 03:47:43.954687611  900875.739770\n",
       "577 1970-01-01 04:03:34.210828973 1160975.802488\n",
       "\n",
       "[578 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5  # Number of parts\n",
    "# The qcut() function discretizes the variable into equal-sized buckets based on rank or \n",
    "# based on sample quantiles.\n",
    "# Create buckets based on quantiles and create a new column 'bucket'\n",
    "buckets = pd.qcut(df_merged['sum'], N)\n",
    "print(buckets.cat.categories.values)\n",
    "\n",
    "df_merged['bucket'] = pd.qcut(df_merged['sum'], N, labels=False)\n",
    "\n",
    "# List to hold dataframes\n",
    "df_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    df_part = df_merged[df_merged['bucket'] == i]\n",
    "    df_list.append(df_part.drop(['bucket'], axis=1).reset_index(drop=True))\n",
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ce894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import bisect\n",
    "\n",
    "\n",
    "# Define the time window in minutes\n",
    "T = 30\n",
    "# Initialize an empty dictionary to hold dataframes\n",
    "\n",
    "epsilon = 0.5\n",
    "hashmaps = []\n",
    "for df in df_list:\n",
    "    hashmap = defaultdict(pd.DataFrame)\n",
    "    # Iterate over the dataframe\n",
    "    for i in range(len(df)):\n",
    "        # Get the timestamp of the current row\n",
    "        timestamp_i = df.loc[i, 'timestamp']\n",
    "\n",
    "        # Initialize lists to hold column data\n",
    "        time_distance = []\n",
    "        ID = []\n",
    "        TWAP = []\n",
    "        SIZES = []\n",
    "        TIMES = []\n",
    "\n",
    "        # Iterate backwards over the dataframe from the current row within the time window\n",
    "        j = i - 1\n",
    "        while j >= 0 and (timestamp_i - df.loc[j, 'timestamp']).total_seconds() <= T*60:\n",
    "            # Calculate the time difference\n",
    "            time_diff = (timestamp_i - df.loc[j, 'timestamp']).total_seconds()\n",
    "\n",
    "            # Add the calculated data to the lists\n",
    "            time_distance.append(time_diff)\n",
    "            ID.append(j)\n",
    "            SIZES.append(df.loc[i, 'sum'])\n",
    "            TIMES.append(df.loc[i, 'timestamp'])\n",
    "            df_j = hashmap[j]\n",
    "            \n",
    "            \n",
    "            if not df_j.empty:\n",
    "                array = df_j['time_distance'].tolist()\n",
    "                idx = bisect.bisect_left(array, time_diff - epsilon)\n",
    "\n",
    "                k = idx\n",
    "                MAX_TWAP = 0\n",
    "                while k < len(array) and abs(array[k] - time_diff) <= epsilon:\n",
    "                    MAX_TWAP = max(MAX_TWAP, df_j.iloc[k]['TWAP'])\n",
    "                    k += 1\n",
    "                \n",
    "                if k != idx:\n",
    "                    TWAP.append(MAX_TWAP + 1)\n",
    "                else:\n",
    "                    TWAP.append(int(0))\n",
    "            else:\n",
    "                TWAP.append(int(0))\n",
    "\n",
    "            j -= 1\n",
    "\n",
    "        # Create a new dataframe from the lists and add it to the hashmap\n",
    "        df_i = pd.DataFrame({'time_distance': time_distance, 'ID': ID, \n",
    "                             'TWAP': TWAP, \"SIZES\": SIZES, \"TIMES\":TIMES})\n",
    "        hashmap[i] = df_i\n",
    "    hashmaps.append(hashmap.copy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_min_threshhold = 10\n",
    "\n",
    "counter_twap = [[] for x in range(N)]\n",
    "for j in range(N):\n",
    "    for i in range(len(hashmaps[j])):\n",
    "        counter_twap[j].append(len(hashmaps[j][i][hashmaps[j][i][\"TWAP\"] >= slice_min_threshhold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ef36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(counter_twap[0], drawstyle='steps-post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = [\"time_distance\", \"ID\", \"TWAP\", \"SIZES\", \"TIMES\"])\n",
    "table = hashmaps[0]\n",
    "order_idx = 240\n",
    "idx = table[order_idx][\"TWAP\"].idxmax()\n",
    "row = table[order_idx].iloc[idx]\n",
    "\n",
    "output.loc[len(output)] = row\n",
    "TWAP_COUNTER = row[\"TWAP\"]\n",
    "\n",
    "while TWAP_COUNTER > 0:\n",
    "    TWAP_COUNTER -= 1\n",
    "    temp_table = table[row[\"ID\"]]\n",
    "    temp_table = temp_table[temp_table[\"TWAP\"] == TWAP_COUNTER]\n",
    "    temp_table = temp_table[temp_table[\"time_distance\"] <= row[\"time_distance\"] + epsilon]\n",
    "    temp_table = temp_table[temp_table[\"time_distance\"] >= row[\"time_distance\"] - epsilon]\n",
    "    row = temp_table.iloc[0]\n",
    "    output.loc[len(output)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359822d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dba6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3590a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c87eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
